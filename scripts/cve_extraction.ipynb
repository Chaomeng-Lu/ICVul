{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import time"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T15:37:24.480692Z",
     "start_time": "2024-11-19T15:37:22.435955Z"
    }
   },
   "id": "74bc1a96f1d6ca9e",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def save_data_to_csv(file_name, data):\n",
    "    folder_path = os.path.join(\"..//data\", \"raw\")\n",
    "    csv_file = os.path.join(folder_path, file_name + \".csv\")\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(csv_file, index=False)\n",
    "    \n",
    "    print(f\"Data saved to {csv_file}\")\n",
    "\n",
    "def save_data_to_json(file_name, data):\n",
    "    folder_path = os.path.join(\"..//data\", \"raw\")\n",
    "    json_file = os.path.join(folder_path, file_name + \".json\")\n",
    "    with open(json_file, 'w') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "    print(f\"Data saved to {json_file}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T15:38:24.141987Z",
     "start_time": "2024-11-19T15:38:24.122841Z"
    }
   },
   "id": "52fa3d42036a939e",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched page 1 with 2000 CVEs\n",
      "Fetched page 2 with 2000 CVEs\n",
      "Fetched page 3 with 2000 CVEs\n",
      "Fetched page 4 with 2000 CVEs\n",
      "Fetched page 5 with 2000 CVEs\n",
      "Fetched page 6 with 2000 CVEs\n",
      "Fetched page 7 with 2000 CVEs\n",
      "Fetched page 8 with 2000 CVEs\n",
      "Fetched page 9 with 2000 CVEs\n",
      "Fetched page 10 with 2000 CVEs\n",
      "Fetched page 11 with 2000 CVEs\n",
      "Failed to retrieve data: 503, 0\n",
      "Failed to retrieve data: 503, 1\n",
      "Failed to retrieve data: 503, 2\n",
      "Fetched page 12 with 2000 CVEs\n",
      "Fetched page 13 with 2000 CVEs\n",
      "Fetched page 14 with 2000 CVEs\n",
      "Fetched page 15 with 2000 CVEs\n",
      "Fetched page 16 with 2000 CVEs\n",
      "Fetched page 17 with 2000 CVEs\n",
      "Fetched page 18 with 2000 CVEs\n",
      "Fetched page 19 with 2000 CVEs\n",
      "Fetched page 20 with 2000 CVEs\n",
      "Fetched page 21 with 2000 CVEs\n",
      "Fetched page 22 with 2000 CVEs\n",
      "Fetched page 23 with 2000 CVEs\n",
      "Fetched page 24 with 2000 CVEs\n",
      "Failed to retrieve data: 503, 0\n",
      "Fetched page 25 with 2000 CVEs\n",
      "Fetched page 26 with 2000 CVEs\n",
      "Fetched page 27 with 2000 CVEs\n",
      "Fetched page 28 with 2000 CVEs\n",
      "Fetched page 29 with 2000 CVEs\n",
      "Failed to retrieve data: 503, 0\n",
      "Fetched page 30 with 2000 CVEs\n",
      "Fetched page 31 with 2000 CVEs\n",
      "Fetched page 32 with 2000 CVEs\n",
      "Fetched page 33 with 2000 CVEs\n",
      "Fetched page 34 with 2000 CVEs\n",
      "Fetched page 35 with 2000 CVEs\n",
      "Fetched page 36 with 2000 CVEs\n",
      "Fetched page 37 with 2000 CVEs\n",
      "Fetched page 38 with 2000 CVEs\n",
      "Fetched page 39 with 2000 CVEs\n",
      "Fetched page 40 with 2000 CVEs\n",
      "Fetched page 41 with 2000 CVEs\n",
      "Fetched page 42 with 2000 CVEs\n",
      "Fetched page 43 with 2000 CVEs\n",
      "Fetched page 44 with 2000 CVEs\n",
      "Fetched page 45 with 2000 CVEs\n",
      "Fetched page 46 with 2000 CVEs\n",
      "Fetched page 47 with 2000 CVEs\n",
      "Fetched page 48 with 2000 CVEs\n",
      "Fetched page 49 with 2000 CVEs\n",
      "Fetched page 50 with 2000 CVEs\n",
      "Fetched page 51 with 2000 CVEs\n",
      "Fetched page 52 with 2000 CVEs\n",
      "Fetched page 53 with 2000 CVEs\n",
      "Fetched page 54 with 2000 CVEs\n",
      "Failed to retrieve data: 503, 0\n",
      "Fetched page 55 with 2000 CVEs\n",
      "Fetched page 56 with 2000 CVEs\n",
      "Fetched page 57 with 2000 CVEs\n",
      "Fetched page 58 with 2000 CVEs\n",
      "Fetched page 59 with 2000 CVEs\n",
      "Fetched page 60 with 2000 CVEs\n",
      "Fetched page 61 with 2000 CVEs\n",
      "Fetched page 62 with 2000 CVEs\n",
      "Fetched page 63 with 2000 CVEs\n",
      "Fetched page 64 with 2000 CVEs\n",
      "Fetched page 65 with 2000 CVEs\n",
      "Fetched page 66 with 2000 CVEs\n",
      "Fetched page 67 with 2000 CVEs\n",
      "Fetched page 68 with 2000 CVEs\n",
      "Fetched page 69 with 2000 CVEs\n",
      "Fetched page 70 with 2000 CVEs\n",
      "Fetched page 71 with 2000 CVEs\n",
      "Fetched page 72 with 2000 CVEs\n",
      "Fetched page 73 with 2000 CVEs\n",
      "Fetched page 74 with 2000 CVEs\n",
      "Fetched page 75 with 2000 CVEs\n",
      "Fetched page 76 with 2000 CVEs\n",
      "Fetched page 77 with 2000 CVEs\n",
      "Fetched page 78 with 2000 CVEs\n",
      "Fetched page 79 with 2000 CVEs\n",
      "Fetched page 80 with 2000 CVEs\n",
      "Failed to retrieve data: 503, 0\n",
      "Failed to retrieve data: 503, 1\n",
      "Failed to retrieve data: 503, 2\n",
      "Fetched page 81 with 2000 CVEs\n",
      "Fetched page 82 with 2000 CVEs\n",
      "Fetched page 83 with 2000 CVEs\n",
      "Fetched page 84 with 2000 CVEs\n",
      "Fetched page 85 with 2000 CVEs\n",
      "Fetched page 86 with 2000 CVEs\n",
      "Fetched page 87 with 2000 CVEs\n",
      "Fetched page 88 with 2000 CVEs\n",
      "Fetched page 89 with 2000 CVEs\n",
      "Fetched page 90 with 2000 CVEs\n",
      "Fetched page 91 with 2000 CVEs\n",
      "Fetched page 92 with 2000 CVEs\n",
      "Fetched page 93 with 2000 CVEs\n",
      "Failed to retrieve data: 503, 0\n",
      "Failed to retrieve data: 503, 1\n",
      "Fetched page 94 with 2000 CVEs\n",
      "Fetched page 95 with 2000 CVEs\n",
      "Fetched page 96 with 2000 CVEs\n",
      "Fetched page 97 with 2000 CVEs\n",
      "Fetched page 98 with 2000 CVEs\n",
      "Fetched page 99 with 2000 CVEs\n",
      "Fetched page 100 with 2000 CVEs\n",
      "Fetched page 101 with 2000 CVEs\n",
      "Fetched page 102 with 2000 CVEs\n",
      "Fetched page 103 with 2000 CVEs\n",
      "Fetched page 104 with 2000 CVEs\n",
      "Fetched page 105 with 2000 CVEs\n",
      "Fetched page 106 with 2000 CVEs\n",
      "Fetched page 107 with 2000 CVEs\n",
      "Fetched page 108 with 2000 CVEs\n",
      "Fetched page 109 with 2000 CVEs\n",
      "Fetched page 110 with 2000 CVEs\n",
      "Fetched page 111 with 2000 CVEs\n",
      "Fetched page 112 with 2000 CVEs\n",
      "Fetched page 113 with 2000 CVEs\n",
      "Fetched page 114 with 2000 CVEs\n",
      "Fetched page 115 with 2000 CVEs\n",
      "Fetched page 116 with 2000 CVEs\n",
      "Fetched page 117 with 2000 CVEs\n",
      "Fetched page 118 with 2000 CVEs\n",
      "Fetched page 119 with 2000 CVEs\n",
      "Fetched page 120 with 2000 CVEs\n",
      "Fetched page 121 with 2000 CVEs\n",
      "Fetched page 122 with 2000 CVEs\n",
      "Fetched page 123 with 2000 CVEs\n",
      "Fetched page 124 with 2000 CVEs\n",
      "Fetched page 125 with 2000 CVEs\n",
      "Fetched page 126 with 2000 CVEs\n",
      "Fetched page 127 with 2000 CVEs\n",
      "Fetched page 128 with 2000 CVEs\n",
      "Fetched page 129 with 2000 CVEs\n",
      "Fetched page 130 with 2000 CVEs\n",
      "Fetched page 131 with 2000 CVEs\n",
      "Fetched page 132 with 2000 CVEs\n",
      "Fetched page 133 with 2000 CVEs\n",
      "Fetched page 134 with 2000 CVEs\n",
      "Fetched page 135 with 1509 CVEs\n",
      "No more CVEs to fetch.\n",
      "Data saved to ..//data\\raw\\all_cves.json\n",
      "Data saved to ..//data\\raw\\all_cves.csv\n"
     ]
    }
   ],
   "source": [
    "def fetch_all_cves(base_url, params=None):\n",
    "    all_cves = []\n",
    "    page_number = 0\n",
    "    \n",
    "    while True:\n",
    "        max_retries = 5\n",
    "        retry_count = 0\n",
    "        # Update the parameters with the current page number\n",
    "        params = params or {}\n",
    "        params.update({'startIndex': page_number * 2000})  # NVD API typically returns 2000 items per page\n",
    "        # Make the request to the API\n",
    "        # response = requests.get(base_url, params=params)\n",
    "        while retry_count < max_retries:\n",
    "            response = requests.get(base_url, params=params)\n",
    "            if response.status_code == 200:\n",
    "                break\n",
    "            else:\n",
    "                print(f\"Failed to retrieve data: {response.status_code}, {retry_count}\")\n",
    "                retry_count += 1\n",
    "                time.sleep(5)  # Wait before retrying (5 seconds in this case)\n",
    "        else:\n",
    "            print(\"Max retries reached. Exiting.\")\n",
    "            break\n",
    "\n",
    "        data = response.json()\n",
    "        vulnerabilities = data.get('vulnerabilities', [])\n",
    "\n",
    "        # If no more CVEs are returned, break the loop\n",
    "        if not vulnerabilities:\n",
    "            print(\"No more CVEs to fetch.\")\n",
    "            break\n",
    "\n",
    "        all_cves.extend(vulnerabilities)\n",
    "        \n",
    "        page_number += 1\n",
    "        print(f\"Fetched page {page_number} with {len(vulnerabilities)} CVEs\")\n",
    "\n",
    "\n",
    "    return all_cves\n",
    "\n",
    "# Define the base API endpoint\n",
    "base_url = \"https://services.nvd.nist.gov/rest/json/cves/2.0\"\n",
    "\n",
    "# Optional: Define query parameters \n",
    "params = {'resultsPerPage': 2000}\n",
    "\n",
    "# Fetch all CVEs\n",
    "all_cves = fetch_all_cves(base_url, params)\n",
    " \n",
    "save_data_to_json(\"all_cves\", all_cves)\n",
    "save_data_to_csv(\"all_cves\", all_cves)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T16:49:50.099203Z",
     "start_time": "2024-11-13T15:15:44.932621Z"
    }
   },
   "id": "23641ec9b587d327",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(269509, 1)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('..//data/raw/all_cves.csv')\n",
    "df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T15:37:39.836230Z",
     "start_time": "2024-11-19T15:37:31.473169Z"
    }
   },
   "id": "ede7778d8e458f60",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to ..//data\\raw\\restructured_all_cves.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": "(269509, 26)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to process each CVE JSON record\n",
    "def restructure_cve_data(cve_data):\n",
    "    # print(cve_data)\n",
    "    cve_data = cve_data.get('cve', {})\n",
    "\n",
    "    # Extracting descriptions\n",
    "    desc_en = next((item['value'] for item in cve_data.get('descriptions', []) if item['lang'] == 'en'), '')\n",
    "\n",
    "    # Extracting CVSS metrics\n",
    "    cvss = cve_data.get('metrics', {}).get('cvssMetricV2', [{}])[0].get('cvssData', {})\n",
    "    cvss_data = {\n",
    "        \"CVSS Version\": cvss.get(\"version\", \"\"),\n",
    "        \"CVSS Vector String\": cvss.get(\"vectorString\", \"\"),\n",
    "        \"Access Vector\": cvss.get(\"accessVector\", \"\"),\n",
    "        \"Access Complexity\": cvss.get(\"accessComplexity\", \"\"),\n",
    "        \"Authentication\": cvss.get(\"authentication\", \"\"),\n",
    "        \"Confidentiality Impact\": cvss.get(\"confidentialityImpact\", \"\"),\n",
    "        \"Integrity Impact\": cvss.get(\"integrityImpact\", \"\"),\n",
    "        \"Availability Impact\": cvss.get(\"availabilityImpact\", \"\"),\n",
    "        \"Base Score\": cvss.get(\"baseScore\", 0.0)\n",
    "    }\n",
    "\n",
    "    # Extracting weaknesses\n",
    "    weakness_desc = next((item['description'][0]['value'] for item in cve_data.get('weaknesses', []) if item['description'][0]['lang'] == 'en'), '')\n",
    "\n",
    "    # Extracting references\n",
    "    references = \";\".join(ref['url'] for ref in cve_data.get('references', []))\n",
    "    \n",
    "    patch_urls = []\n",
    "    for reference in cve_data.get('references', []):\n",
    "        if 'Patch' in reference.get('tags', []):\n",
    "            patch_urls.append(reference['url'])\n",
    "    patch = ';'.join(patch_urls)\n",
    "\n",
    "    # Creating a dictionary of the CVE data\n",
    "    return {\n",
    "        \"CVE ID\": cve_data.get('id', ''),\n",
    "        \"Source Identifier\": cve_data.get('sourceIdentifier', ''),\n",
    "        \"Published Date\": cve_data.get('published', ''),\n",
    "        \"Last Modified Date\": cve_data.get('lastModified', ''),\n",
    "        \"Vulnerability Status\": cve_data.get('vulnStatus', ''),\n",
    "        \"Description\": desc_en,\n",
    "        **cvss_data,\n",
    "        \"Base Severity\": cve_data.get('metrics', {}).get('cvssMetricV2', [{}])[0].get(\"baseSeverity\", \"\"),\n",
    "        \"Exploitability Score\": cve_data.get('metrics', {}).get('cvssMetricV2', [{}])[0].get(\"exploitabilityScore\", 0.0),\n",
    "        \"Impact Score\": cve_data.get('metrics', {}).get('cvssMetricV2', [{}])[0].get(\"impactScore\", 0.0),\n",
    "        \"acInsufInfo\": cve_data.get('metrics', {}).get('cvssMetricV2', [{}])[0].get(\"acInsufInfo\", False),\n",
    "        \"Obtain All Privilege\": cve_data.get('metrics', {}).get('cvssMetricV2', [{}])[0].get(\"obtainAllPrivilege\", False),\n",
    "        \"Obtain User Privilege\": cve_data.get('metrics', {}).get('cvssMetricV2', [{}])[0].get(\"obtainUserPrivilege\", False),\n",
    "        \"Obtain Other Privilege\": cve_data.get('metrics', {}).get('cvssMetricV2', [{}])[0].get(\"obtainOtherPrivilege\", False),\n",
    "        \"User Interaction Required\": cve_data.get('metrics', {}).get('cvssMetricV2', [{}])[0].get(\"userInteractionRequired\", False),\n",
    "        \"CWE ID\": weakness_desc,\n",
    "        \"Reference URLs\": references,\n",
    "        \"Patch URL\": patch\n",
    "    }\n",
    "\n",
    "with open('..//data/raw/all_cves.json', 'r') as file:\n",
    "    cve_data = json.load(file)\n",
    "    \n",
    "restructured_df = pd.DataFrame([restructure_cve_data(cve) for cve in cve_data])\n",
    "\n",
    "# Save the result to a new CSV file\n",
    "save_data_to_csv(\"restructured_all_cves\", restructured_df)\n",
    "restructured_df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T15:38:58.166195Z",
     "start_time": "2024-11-19T15:38:28.411713Z"
    }
   },
   "id": "f790c09ae65de5da",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7a1078ccd1c32f9e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
